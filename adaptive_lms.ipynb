{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions and Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conc(t, n):\n",
    "    tmp = t\n",
    "    for _ in range(n-1):\n",
    "        t = np.concatenate((t,tmp))\n",
    "    return t\n",
    "#################################################################\n",
    "def make_noise(sig, snr):\n",
    "    #function to make noise signal based on given SNR\n",
    "    k = 10**(-snr/20) #signal noise ratio\n",
    "    variance = k*np.var(sig)\n",
    "    noise = np.random.normal(0, scale=variance  ,size=len(sig)) #(mean, variance, length)\n",
    "    return noise, variance\n",
    "##################################################################\n",
    "def gaussian_kernel(u1, u2, h):\n",
    "    #Gaussian kernel for 2 signals\n",
    "    k = np.exp(-(np.sum((np.array(u1)-np.array(u2))**2, axis=0))*h)\n",
    "    return k\n",
    "###################################################################    \n",
    "def LMS_test(signal, noisy, w):\n",
    "    #function to test the LMS filter \n",
    "    test_error=[]\n",
    "    filtered_signal=[]\n",
    "    filter_size=len(w)\n",
    "    for i in range(len(signal)-filter_size):\n",
    "        f = np.dot(w, noisy[i:i+filter_size])\n",
    "        filtered_signal.append(f)\n",
    "        e = signal[i+filter_size]-f\n",
    "        test_error.append(e**2)\n",
    "    general_error = np.mean(test_error)\n",
    "    return filtered_signal, general_error\n",
    "####################################################################\n",
    "def LMS_train(desire, inp, t_signal, t_noisy, filter_size, lr, epochs=1):\n",
    "    #function to train the LMS filter\n",
    "    w = np.zeros(filter_size)\n",
    "    error = []\n",
    "    for _ in range(epochs):\n",
    "        for i in range (len(desire)-filter_size):\n",
    "            e = desire[i+filter_size] - np.dot(w, inp[i:i+filter_size])\n",
    "            w = w + lr*e*inp[i:i+filter_size]\n",
    "\n",
    "        #test the filter every 50 iterations\n",
    "            if i%50 == 0:\n",
    "                filtered_signal, test_error = LMS_test(t_signal, t_noisy,w)\n",
    "                error.append(test_error)\n",
    "    return w, error, filtered_signal\n",
    "####################################################################\n",
    "def KLMS_train(desire, inp,test_data, test_noisy, filter_size, lr, kernel, h, epochs=1):\n",
    "    #train function of kernel LMS\n",
    "    desire = conc(desire, epochs)\n",
    "    inp = conc(inp, epochs)\n",
    "    delay = filter_size\n",
    "    N_tr = len(desire)-delay\n",
    "    e = np.zeros(len(desire))\n",
    "    error = []\n",
    "    a = []\n",
    "    f = []\n",
    "    e[0]= desire[delay]\n",
    "    u = np.zeros((delay, N_tr))\n",
    "    for j in range(N_tr):\n",
    "        u[:,j]=inp[j:j+delay]\n",
    "    a.append(lr*e[0])\n",
    "    for i in range(N_tr-1):\n",
    "        k = gaussian_kernel( u[:,i+1:i+2], u[:,:i+1], h)\n",
    "        ff = np.dot(a[-len(k):], k)\n",
    "        f.append(ff)\n",
    "        e[i+1]= desire[i+delay]-ff\n",
    "        a.append(lr*e[i+1])\n",
    "        #test #######\n",
    "        if i%50 == 0: \n",
    "            #print(np.int(i/len(desire)*100), \"%\")\n",
    "            klms_filtered, error_klms = KLMS_test(test_data, test_noisy, desire,filter_size, a, h)\n",
    "            error.append(np.mean(np.asarray(error_klms)**2))\n",
    "#     print(\"train done\")\n",
    "    return a, error\n",
    "#######################################################################\n",
    "def KLMS_test(test_signal,test_noisy, train_signal,filter_size, a, h):\n",
    "    #test funtion for kernel LMS\n",
    "    delay = filter_size\n",
    "    error = []\n",
    "    N_tr = len(train_signal)-delay\n",
    "    N_te = len(test_signal)-delay\n",
    "    output = np.zeros(len(test_signal))\n",
    "    d = np.zeros((delay, N_tr))\n",
    "    x = np.zeros((delay, N_te))\n",
    "    for j in range(N_tr):\n",
    "        d[:,j]=train_signal[j:j+delay]\n",
    "    for j in range(N_te):\n",
    "        x[:,j]=test_noisy[j:j+delay]\n",
    "    output[:delay] = test_signal[:delay]\n",
    "    for i in range(N_te):\n",
    "        j = i+delay\n",
    "        k = gaussian_kernel(x[:, i:i+1], d[:,:len(a)], h)\n",
    "#         print(np.asarray(a).shape)\n",
    "#         print(k.shape)\n",
    "        output[j] = np.dot(np.asarray(a), k)\n",
    "#         print(output[i])\n",
    "        error.append((test_signal[j] - output[j])**2)\n",
    "    #print(\"test  done\")\n",
    "    return output, error\n",
    "\n",
    "def load_data(non_linear = False):\n",
    "    #loading data - extra non-linearity can be added by setting non_linear = True\n",
    "    mat_test = \"C:/Users/nikolatesla/Desktop/Apative FIlter/Test.mat\"\n",
    "    mat_train = \"C:/Users/nikolatesla/Desktop/Apative FIlter/Training.mat\"\n",
    "    snr = 1\n",
    "    xt= loadmat(mat_test)[\"x_test\"].reshape((10000))\n",
    "    x = loadmat(mat_train)[\"x_training\"].reshape((500))\n",
    "    noise, noise_variance = make_noise(xt, snr)\n",
    "    y = x + noise[:len(x)]\n",
    "    yt = xt + noise\n",
    "    if non_linear:\n",
    "        x = x**3 - np.sin(x)\n",
    "        y = y**3 - np.sin(y)\n",
    "        xt = xt**3 - np.sin(xt)\n",
    "        yt = yt**3 - np.sin(yt)\n",
    "    return x, y, xt, yt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, train_noisy, test, test_noisy = load_data(non_linear=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(10,5))\n",
    "# fig.add_subplot(1,2,1)\n",
    "# plt.plot(train)\n",
    "# plt.title(\"desired signal\")\n",
    "# fig.add_subplot(1,2,2)\n",
    "# plt.plot(train_noisy)\n",
    "# plt.title(\"noisy signal\")\n",
    "# plt.savefig(\"signals.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimated h:  1.6560274770024002\n",
      "estimated lr limit: 0.1167\n",
      "alphas:  [1.8232e+01 1.7261e+00 6.0270e-01 3.0360e-01 1.8230e-01 1.1400e-02\n",
      " 3.7000e-03 1.8000e-03]\n",
      "learning rates:  [0.001, 0.008, 0.04, 0.1]\n",
      "filter sizes:  [5, 10, 20, 50]\n"
     ]
    }
   ],
   "source": [
    "#pramater estimation\n",
    "\n",
    "#alpha: kernel parameter\n",
    "signal = train\n",
    "iqr = np.subtract(*np.percentile(signal, [75, 25]))\n",
    "h = 1.06* np.minimum(np.std(signal), iqr/1.34)* len(signal)**(1/5)\n",
    "print(\"estimated h: \",h)\n",
    "hh = np.concatenate((np.linspace(h/10, h, 4, endpoint=False), np.linspace(h, 10*h, 4)))\n",
    "\n",
    "alphas = np.around((0.5 * 1/hh**2), decimals=4)\n",
    "\n",
    "#learning rate\n",
    "import scipy.signal\n",
    "filter_size = 10\n",
    "n = len(signal)-filter_size\n",
    "u = np.zeros((filter_size, n))\n",
    "for j in range(n):\n",
    "        u[:,j]=signal[j:j+filter_size]\n",
    "\n",
    "R = np.corrcoef(u)\n",
    "lr_value = np.around(1/np.max(np.linalg.eigvals(R)), decimals=4)\n",
    "print(\"estimated lr limit:\", lr_value)\n",
    "lr_kernel = [0.001, 0.008, 0.04, 0.1]\n",
    "\n",
    "#filter size\n",
    "filter_size_kernel = [5,10,20,50]\n",
    "print(\"alphas: \", alphas)\n",
    "print(\"learning rates: \", lr_kernel)\n",
    "print(\"filter sizes: \", filter_size_kernel)\n",
    "# plt.figure(figsize=(10,10))\n",
    "# xx = np.linspace(-100, 100, 1000)\n",
    "# for a in iter(alphas):\n",
    "#     y = np.exp((-(xx)**2)*a)\n",
    "#     plt.plot(xx, y, label=\"alpha=\"+np.str(a))\n",
    "# plt.legend()\n",
    "# plt.xlabel(\"u-x\")\n",
    "# plt.ylabel(\"Kernel_Ausgang\")\n",
    "# plt.savefig(\"distributions.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training LMS filter with different parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "365b783389bf4a9bbdf22f15da28a5cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#LMS \n",
    "lr_lms = lr_kernel\n",
    "filter_size = filter_size_kernel\n",
    "epochs = 1\n",
    "result_lms = pd.DataFrame(columns=[\"lr\", \"size\", \"error\", \"w\", \"name\"])\n",
    "n_cases = len(lr_lms)*len(filter_size)\n",
    "with tqdm_notebook(total=n_cases) as pbar:\n",
    "    for lr, size in itertools.product(lr_lms, filter_size):\n",
    "        w, e, filtered_signal= LMS_train(train, train_noisy, test[:1000], test_noisy[:1000], size, lr , epochs=epochs)\n",
    "        name = \"  f_size=\"+np.str(size) + \" lr=\"+np.str(lr)\n",
    "        result_lms = result_lms.append(pd.DataFrame([[lr, size, e, w, name]], columns=[\"lr\", \"size\", \"error\", \"w\", \"name\"]), \n",
    "                                     ignore_index=True)\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross_Validation LMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(filter_size)-1):\n",
    "#     fig = plt.figure(figsize=(10,40))\n",
    "#     n=0\n",
    "#     for j in range(n_cases):\n",
    "#         if result_lms[\"size\"][j] == filter_size[i] or result_lms[\"size\"][j] == filter_size[i+1]:\n",
    "#             fig.add_subplot(8,2,n+1)\n",
    "#             plt.plot(result_lms[\"error\"][j], \"*-\")\n",
    "#             plt.title(result_lms[\"name\"][j])\n",
    "#             plt.xlabel(\"Iteration\")\n",
    "#             plt.ylabel(\"Error\")\n",
    "#             n += 1\n",
    "#     address = \"size_lms=\"+np.str(filter_size[i])+\"_\"+np.str(filter_size[i+1])+\".png\"\n",
    "#     plt.savefig(address)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training KLMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "893e768aa4c34afa95832091b2b5ba33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=128), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_klms = pd.DataFrame(columns=[\"lr\", \"alpha\", \"size\", \"error\", \"name\"])\n",
    "error = []\n",
    "n_cases = len(filter_size_kernel)*len(alphas)*len(lr_kernel)\n",
    "epochs = 1\n",
    "with tqdm_notebook(total = n_cases) as pbar:\n",
    "    for lr, size, alpha in itertools.product(lr_kernel, filter_size_kernel, alphas):\n",
    "        name = \"alpha=\"+np.str(alpha)+\"  f_size=\"+np.str(size) + \" lr=\"+np.str(lr)\n",
    "        _, e = KLMS_train(train, train_noisy ,test[:1000], test_noisy[:1000], size , lr, \"gaussian\", alpha, epochs=epochs)\n",
    "        result_klms = result_klms.append(pd.DataFrame([[lr,alpha, size, e, name]], columns=[\"lr\", \"alpha\", \"size\", \"error\", \"name\"]), \n",
    "                                     ignore_index=True)\n",
    "        pbar.update(1)\n",
    "        \n",
    "import winsound\n",
    "duration = 3000  # milliseconds\n",
    "freq = 880  # Hz\n",
    "winsound.Beep(freq, duration)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross_Validation KLMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for j in range(len(lr_kernel)):\n",
    "#     fig = plt.figure(figsize=(30,45))\n",
    "#     n =0\n",
    "#     for i in range(len(alphas)*len(lr_kernel)*len(filter_size_kernel)):\n",
    "#         if result_klms[\"lr\"][i] == lr_kernel[j]:\n",
    "#             fig.add_subplot(8, 4, n+1)\n",
    "#             n +=1 \n",
    "#             plt.plot(result_klms[\"error\"][i], \"*-\")\n",
    "#             plt.title(result_klms[\"name\"][i])\n",
    "#             plt.xlabel(\"Iteration\")\n",
    "#             plt.ylabel(\"Error\")\n",
    "#     address = \"lr=\"+np.str(lr_kernel[j])+\".png\"\n",
    "#     plt.savefig(address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison between LMS and KLMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "filter_size = 20 \n",
    "alpha = 0.1823\n",
    "_, e_klms = KLMS_train(train, train_noisy ,test, test_noisy, filter_size , 0.04, \"gaussian\", alpha, epochs=epochs)\n",
    "w, e_lms, _= LMS_train(train, train_noisy, test, test_noisy, filter_size, 0.008 , epochs=epochs)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(e_lms, label=\"LMS\")\n",
    "plt.plot(e_klms, label=\"KLMS\")\n",
    "plt.title(\"alpha: \"+ np.str(alpha)+\" filter_size: \"+np.str(filter_size))\n",
    "plt.legend()\n",
    "plt.savefig(\"ver2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
